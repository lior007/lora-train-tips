# מדריך מקיף ומאוחד לאימון LoRA

## 1. פרמטרים קריטיים לאימון

### Linear (Network Dimension)
גודל הדרגה (rank) של מטריצות LoRA - פרמטר קריטי לאיכות האימון

#### השפעת הערך:
* ערך גבוה:
  - יכולת למידה טובה יותר
  - צורך יותר זיכרון
  - למידה מעמיקה יותר של פרטים
* ערך נמוך:
  - חסכוני בזיכרון
  - יכולת למידה מוגבלת יותר
  - מתאים למודלים פשוטים

#### ערכים מומלצים:
* **4-8**: למודלים קטנים או מוגבלי זיכרון
* **16-32**: לרוב המקרים (מומלץ)
* **64+**: למודלים גדולים עם הרבה זיכרון

### Batch Size - המלצה חשובה!
**המלצה חד משמעית: השתמש ב-batch_size = 1**
* תוצאות יותר עקביות ויציבות
* למידה יותר מדויקת של המאפיינים
* פחות רעש בתהליך האימון
* עובד טוב במיוחד עם Flux LoRA
* מונע בעיות זיכרון אפשריות

### Data Types (dtype)
פורמט הנתונים לשמירת המודל

#### float16:
* חצי דיוק
* חוסך זיכרון
* מספיק למרבית המקרים
* **מומלץ!**

#### float32:
* דיוק מלא
* צורך יותר זיכרון
* נדרש במקרים מיוחדים

### צעדים ואפוקות
```
צעדים באפוקה = (מספר תמונות × repeats) ÷ batch_size
מספר אפוקות = סך כל הצעדים ÷ צעדים באפוקה
```

| פרמטר | תיאור | המלצות |
|--------|---------|----------|
| steps | מספר הצעדים הכולל באימון | - סט קטן (עד 20 תמונות): 1000-1500 צעדים<br>- סט בינוני (20-50 תמונות): 1500-2500 צעדים<br>- סט גדול (50+ תמונות): 2500+ צעדים |
| repeats | כמה פעמים לחזור על כל תמונה ברצף | - 1 ברוב המקרים (מומלץ)<br>- 2+ רק במקרים מיוחדים |

## 2. פרמטרים לניהול האימון

### Learning Rate (lr)
קצב הלמידה של המודל - ערך מומלץ: **0.0001**

#### משמעות הערך:
* קצב נמוך (0.0001):
  - למידה יציבה יותר
  - סיכוי נמוך ל-overfitting
  - מתאים לרוב המקרים
* קצב גבוה יותר:
  - למידה מהירה יותר
  - סיכון גבוה יותר לחוסר יציבות
  - דורש ניטור קפדני

### max_step_saves_to_keep
מספר הגרסאות המקסימלי שיישמר במהלך האימון

דוגמה עם 2000 צעדים ו-max_step_saves_to_keep: 4:
```
יישמרו רק 4 נקודות השמירה האחרונות:
1250, 1500, 1750, 2000
* כל השמירות הקודמות יימחקו אוטומטית
```

### performance_log_every
תדירות רישום מדדי ביצועים במהלך האימון

#### נתונים שנרשמים:
* ערכי Loss
* זמני עיבוד
* שימוש בזיכרון

**ערך מומלץ: 10** - מספק מעקב מדויק מספיק בלי להאט את האימון

### caption_dropout_rate
שיעור השמטת כיתובים במהלך האימון

#### משמעות ערך 0.05:
* 5% מהזמן הכיתוב יושמט
* מטרות:
  - הגברת גמישות המודל
  - מניעת תלות יתר בכיתובים
  - שיפור יכולת ההכללה

## 3. טיפים לאיכות אימון טובה

### בחירת תמונות
* מינימום 15-20 תמונות לתוצאות טובות
* גיוון בזוויות, תאורה ורקעים
* רזולוציה עקבית בין התמונות
* איכות תמונה טובה ללא רעשים

### הגדרות אופטימליות
* learning rate: בין 1e-4 ל-8e-4
* network_dim: 4-32 (תלוי בכמות הזיכרון)
* resolution: 512-1024 (תלוי באיכות התמונות המקוריות)
* optimizer: adamw8bit (חסכוני בזיכרון ויעיל)

## 4. דוגמאות מספריות

### חישוב אפוקות עם batch_size = 1 (מומלץ)
עם 30 תמונות ו-batch_size = 1:
```
repeats = 1 (מומלץ):
- צעדים באפוקה = 30 × 1 ÷ 1 = 30
- עם 1800 צעדים = 60 אפוקות

repeats = 2:
- צעדים באפוקה = 30 × 2 ÷ 1 = 60
- עם 1800 צעדים = 30 אפוקות
```

## 5. מעקב וניטור

### נקודות מעקב חשובות
* שמירת מודל תקופתית (למשל כל 250 צעדים)
* יצירת תמונות לבדיקה במהלך האימון
* מעקב אחרי ערך ה-loss

### סימנים לבעיות באימון
* loss שלא יורד או קופץ מאוד
* תמונות שנראות זהות בכל דגימה
* תמונות שנראות מעוותות או מטושטשות
* שימוש יתר במאפיין ספציפי מהתמונות

### למה לא להשתמש ב-batch_size גדול יותר?
* יכול לגרום לחוסר יציבות באימון
* עלול לפספס פרטים עדינים בתמונות
* צורך יותר זיכרון ללא תועלת משמעותית
* פחות מתאים לאימון LoRA ממוקד

## 6. המלצות לשיפור תוצאות

### המלצות כלליות
* התחל עם ערכי ברירת המחדל המומלצים
* שנה פרמטר אחד בכל פעם
* תעד את כל השינויים והתוצאות
* גבה את המודלים החשובים
* בדוק תוצאות עם מגוון prompts

### טיפים נוספים לאימון מוצלח
* התחל עם batch_size = 1 ו-repeats = 1
* שמור על יחס טוב בין מספר התמונות למספר הצעדים
* הקפד על prompts טובים בתמונות הדגימה
* נסה שינויים קטנים בפרמטרים אחרים (learning rate, network_dim)
* תעד את התוצאות והשינויים שעשית

### חשיבות התיעוד והמעקב
* שמור את הגדרות האימון לכל ניסוי
* תעד את איכות התוצאות
* השווה בין הגדרות שונות
* למד מניסיונות קודמים

### סיכום חשיבות הפרמטרים העיקריים
* batch_size = 1: יציבות ודיוק
* repeats = 1: יעילות באימון
* network_dim: איזון בין יכולת למידה לזיכרון
* learning_rate: איזון בין מהירות ליציבות
* dtype = float16: יעילות בזיכרון

### דגשים סופיים
* התחל עם הגדרות בסיסיות ופשוטות
* הבן את ההשפעה של כל פרמטר
* התאם את ההגדרות בהדרגה לפי הצורך
* שמור על תיעוד מסודר של השינויים והתוצאות
* הקפד על גיבוי המודלים החשובים
